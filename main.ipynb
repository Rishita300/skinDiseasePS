{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class driveFile:\n",
    "  def __init__(self):\n",
    "    self.path=\"\"\n",
    "  def dataload(self,folder_path):\n",
    "    img=[]\n",
    "    label=[]\n",
    "    import os\n",
    "    self.path1=os.path.join(self.path,folder_path)\n",
    "    \n",
    "    if os.path.exists(self.path1):\n",
    "      for i in os.listdir(self.path1):\n",
    "        self.dis_path=os.path.join(self.path1,i)\n",
    "        # /content/drive/MyDrive/train_set/BA- cellulitis\n",
    "        if os.path.exists(self.dis_path) and '.DS_Store' not in self.dis_path:\n",
    "          for j in os.listdir(self.dis_path):\n",
    "           if j.endswith(('.jpg', '.png', '.jpeg')):\n",
    "              self.img_path = os.path.join(self.dis_path, j)\n",
    "              loaded_img= self.imgload(self.img_path)\n",
    "              if loaded_img is not None:\n",
    "                img.append(loaded_img)\n",
    "                label.append(i)\n",
    "              else:\n",
    "                 print(\"Skipping non-image file:\", j)\n",
    "          else:\n",
    "              print(\"Skipping invalid path or .DS_Store:\", self.dis_path)\n",
    "              continue\n",
    "      return np.array(img), np.array(label)\n",
    "    else:\n",
    "      return \"patherror\",\"patherror\"\n",
    "\n",
    "\n",
    "\n",
    "  def imgload(self,imgpath):\n",
    "    img=cv2.imread(imgpath)\n",
    "    if img is None:\n",
    "      print(f\"Failed to load image at {imgpath}\")\n",
    "      return None\n",
    "    img=cv2.resize(img,(20,20))\n",
    "    # v imp, usually 224*224 but here 20*20 \"downsampling or using a smaller image resolution before flattening it.\"\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    img=img.astype('float32')/255.0\n",
    "    img_array=np.array(img)\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping invalid path or .DS_Store: train_set/FU-athlete-foot\n",
      "Skipping invalid path or .DS_Store: train_set/BA- cellulitis\n"
     ]
    }
   ],
   "source": [
    "\n",
    "drive=driveFile()\n",
    "images,labels=drive.dataload('train_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input=None\n",
    "        self.output=None\n",
    "    def forward(self,input):\n",
    "        # to be overridden \n",
    "        pass \n",
    "    def backward(self,output_gradient,learning_rate):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        self.weights=np.random.randn(output_size,input_size)*0.01\n",
    "        self.bias=np.random.randn(output_size,1)\n",
    "    def forward(self,input):\n",
    "        self.input=input\n",
    "        return np.dot(self.weights,self.input)+self.bias\n",
    "    def backward(self,output_gradient,learning_rate):\n",
    "        w_gradient = np.dot(output_gradient, self.input.T)  # (output_size, input_size)\n",
    "        b_gradient = np.sum(output_gradient, axis=1, keepdims=True)  # (output_size, 1)\n",
    "        input_gradient = np.dot(self.weights.T, output_gradient)  # (input_size, batch_size)\n",
    "        self.weights-=learning_rate * w_gradient\n",
    "        self.bias-=learning_rate * b_gradient\n",
    "        return input_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation(Layer):\n",
    "    def __init__(self,activation,activatn_derivative):\n",
    "        #activation is a variable pointing to a activation method,for ex sigmoid\n",
    "        self.activation=activation\n",
    "        self.activatn_derivative=activatn_derivative\n",
    "    def forward(self,input):\n",
    "        self.input=input\n",
    "        return self.activation(self.input)\n",
    "    def backward(self,output_gradient,learning_rate):\n",
    "        return np.multiply(output_gradient,self.activatn_derivative(self.input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Activation):\n",
    "    def __init__(self):\n",
    "        def sigmoid(x):\n",
    "            return 1/(1+np.exp(-x))\n",
    "        def sigmoid_derivative(x):\n",
    "            s=sigmoid(x)\n",
    "            return s*(1-s)\n",
    "        super().__init__(sigmoid,sigmoid_derivative)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(Layer):\n",
    "    def __init__(self,loss_fn,loss_fn_Derivative):\n",
    "        self.loss_fn=loss_fn\n",
    "        self.loss_fn_Derivative=loss_fn_Derivative\n",
    "    def forward(self,y_pred,y_true):\n",
    "        self.y_pred = y_pred\n",
    "        self.y_true = y_true\n",
    "        return self.loss_fn(y_pred, y_true)\n",
    "    def backward(self,y_pred,y_true):\n",
    "        return self.loss_fn_Derivative(y_pred,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryCrossEntropy(Loss):\n",
    "    def __init__(self):\n",
    "        def bce(y_pred,y_true):\n",
    "            y_pred = np.clip(y_pred, 1e-10, 1 - 1e-10)  # Prevent extreme values\n",
    "            return -np.mean((y_true*np.log(y_pred))+((1-y_true)*np.log(1-y_pred)))\n",
    "        def bce_derivative(y_pred,y_true):\n",
    "            y_pred = np.clip(y_pred, 1e-10, 1 - 1e-10)  # Avoid division by zero\n",
    "            return -(y_true / y_pred) + ((1 - y_true) / (1 - y_pred))\n",
    "        super().__init__(bce,bce_derivative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, layers, learning_rate=0.01, batch_size=32, epochs=10):\n",
    "        self.layers = layers\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.loss_fn = BinaryCrossEntropy()\n",
    "\n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "        return X\n",
    "\n",
    "    def backward(self, loss_gradient):\n",
    "        for layer in reversed(self.layers):\n",
    "            loss_gradient = layer.backward(loss_gradient, self.learning_rate)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        for epoch in range(self.epochs):\n",
    "            num_samples = X.shape[0]\n",
    "            index=np.arange(num_samples)\n",
    "            np.random.shuffle(index)\n",
    "            X=X[index]\n",
    "            y=y[index]\n",
    "            for i in range(0, num_samples, self.batch_size):\n",
    "                if(i+self.batch_size==num_samples):\n",
    "                    X_batch = X[i:num_samples]\n",
    "                    y_batch = y[i:num_samples]\n",
    "                else:\n",
    "                    X_batch = X[i:i + self.batch_size]\n",
    "                    y_batch = y[i:i + self.batch_size]\n",
    "\n",
    "                # Forward pass\n",
    "                predictions = self.forward(X_batch.T)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = self.loss_fn.forward(predictions, y_batch.T)\n",
    "                print(f\"Epoch {epoch + 1}, Batch {i // self.batch_size + 1}, Loss: {loss}\")\n",
    "\n",
    "                # Backward pass\n",
    "                loss_gradient = self.loss_fn.backward(predictions, y_batch.T)\n",
    "                self.backward(loss_gradient)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = self.forward(X.T)\n",
    "        return (predictions >= 0.5).astype(int).flatten()\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        accuracy = np.mean(predictions == y)\n",
    "        print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "        return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 1, Loss: 0.6858312070151591\n",
      "Epoch 1, Batch 2, Loss: 0.7919152053159743\n",
      "Epoch 1, Batch 3, Loss: 0.9277544386079506\n",
      "Epoch 1, Batch 4, Loss: 0.2432375542185935\n",
      "Epoch 1, Batch 5, Loss: 1.5050042987121282\n",
      "Epoch 1, Batch 6, Loss: 0.5438262854095194\n",
      "Epoch 1, Batch 7, Loss: 0.4827561481216765\n",
      "Epoch 1, Batch 8, Loss: 1.3585443013287963\n",
      "Epoch 1, Batch 9, Loss: 2.162336012254296\n",
      "Epoch 1, Batch 10, Loss: 1.8373498595251125\n",
      "Epoch 1, Batch 11, Loss: 3.0453029910646476\n",
      "Epoch 1, Batch 12, Loss: 1.0098189843480512\n",
      "Epoch 1, Batch 13, Loss: 1.2796390152460293\n",
      "Epoch 1, Batch 14, Loss: 0.6317174986053002\n",
      "Epoch 1, Batch 15, Loss: 1.0717824334778279\n",
      "Epoch 1, Batch 16, Loss: 1.3992290278248474\n",
      "Epoch 1, Batch 17, Loss: 0.6742949446097518\n",
      "Epoch 1, Batch 18, Loss: 0.5874134938173561\n",
      "Epoch 1, Batch 19, Loss: 0.9887244216353023\n",
      "Epoch 1, Batch 20, Loss: 0.8150771748634282\n",
      "Epoch 1, Batch 21, Loss: 0.789962516935327\n",
      "Epoch 1, Batch 22, Loss: 0.6744753226978046\n",
      "Epoch 1, Batch 23, Loss: 0.8145809120001659\n",
      "Epoch 1, Batch 24, Loss: 0.9209617322537599\n",
      "Epoch 1, Batch 25, Loss: 1.442949785712468\n",
      "Epoch 2, Batch 1, Loss: 0.6776958243444637\n",
      "Epoch 2, Batch 2, Loss: 0.48596109285778316\n",
      "Epoch 2, Batch 3, Loss: 1.2935904887676979\n",
      "Epoch 2, Batch 4, Loss: 1.7405437239707273\n",
      "Epoch 2, Batch 5, Loss: 1.8367573705703166\n",
      "Epoch 2, Batch 6, Loss: 0.9304108610220456\n",
      "Epoch 2, Batch 7, Loss: 0.8889698769791989\n",
      "Epoch 2, Batch 8, Loss: 1.3679460717848406\n",
      "Epoch 2, Batch 9, Loss: 0.5997694210357033\n",
      "Epoch 2, Batch 10, Loss: 0.9109789630614278\n",
      "Epoch 2, Batch 11, Loss: 1.1597140843716773\n",
      "Epoch 2, Batch 12, Loss: 0.5250972452540292\n",
      "Epoch 2, Batch 13, Loss: 0.6289115942930023\n",
      "Epoch 2, Batch 14, Loss: 0.8080213842150432\n",
      "Epoch 2, Batch 15, Loss: 1.5861452901477118\n",
      "Epoch 2, Batch 16, Loss: 1.6567320299021597\n",
      "Epoch 2, Batch 17, Loss: 2.0086142477409528\n",
      "Epoch 2, Batch 18, Loss: 0.5951099246542654\n",
      "Epoch 2, Batch 19, Loss: 0.43898638653866945\n",
      "Epoch 2, Batch 20, Loss: 1.2491863004597077\n",
      "Epoch 2, Batch 21, Loss: 0.9580004915385002\n",
      "Epoch 2, Batch 22, Loss: 0.5620161414041501\n",
      "Epoch 2, Batch 23, Loss: 0.6225977490951697\n",
      "Epoch 2, Batch 24, Loss: 0.8410541570245014\n",
      "Epoch 2, Batch 25, Loss: 2.2526244685094854\n",
      "Epoch 3, Batch 1, Loss: 1.144250728589542\n",
      "Epoch 3, Batch 2, Loss: 0.998640404176107\n",
      "Epoch 3, Batch 3, Loss: 0.5928098529126808\n",
      "Epoch 3, Batch 4, Loss: 0.48345312385664535\n",
      "Epoch 3, Batch 5, Loss: 0.5306232983155039\n",
      "Epoch 3, Batch 6, Loss: 1.2293455454273665\n",
      "Epoch 3, Batch 7, Loss: 2.084858247226737\n",
      "Epoch 3, Batch 8, Loss: 0.702965533310642\n",
      "Epoch 3, Batch 9, Loss: 1.5880091543832096\n",
      "Epoch 3, Batch 10, Loss: 0.9250324618635396\n",
      "Epoch 3, Batch 11, Loss: 0.2820695041326292\n",
      "Epoch 3, Batch 12, Loss: 0.971135229020133\n",
      "Epoch 3, Batch 13, Loss: 1.2774088825521661\n",
      "Epoch 3, Batch 14, Loss: 1.3212659696955678\n",
      "Epoch 3, Batch 15, Loss: 0.34515309483840445\n",
      "Epoch 3, Batch 16, Loss: 1.2048342871465003\n",
      "Epoch 3, Batch 17, Loss: 1.0229829894617708\n",
      "Epoch 3, Batch 18, Loss: 0.5227306804445926\n",
      "Epoch 3, Batch 19, Loss: 0.6021888064150905\n",
      "Epoch 3, Batch 20, Loss: 0.7828936852415755\n",
      "Epoch 3, Batch 21, Loss: 0.6829610138312803\n",
      "Epoch 3, Batch 22, Loss: 1.1987121861015944\n",
      "Epoch 3, Batch 23, Loss: 3.484847258629629\n",
      "Epoch 3, Batch 24, Loss: 1.7996897488001964\n",
      "Epoch 3, Batch 25, Loss: 0.513251485358391\n",
      "Epoch 4, Batch 1, Loss: 0.6234760184812133\n",
      "Epoch 4, Batch 2, Loss: 0.5932146693295665\n",
      "Epoch 4, Batch 3, Loss: 0.4096075941645755\n",
      "Epoch 4, Batch 4, Loss: 0.8508103146608512\n",
      "Epoch 4, Batch 5, Loss: 2.1825420406790315\n",
      "Epoch 4, Batch 6, Loss: 2.6921430362416734\n",
      "Epoch 4, Batch 7, Loss: 3.1656923967439905\n",
      "Epoch 4, Batch 8, Loss: 1.442012024625236\n",
      "Epoch 4, Batch 9, Loss: 0.9883433593545431\n",
      "Epoch 4, Batch 10, Loss: 1.1090069460865484\n",
      "Epoch 4, Batch 11, Loss: 0.4524604399980624\n",
      "Epoch 4, Batch 12, Loss: 0.5309974257795524\n",
      "Epoch 4, Batch 13, Loss: 0.6473790623510673\n",
      "Epoch 4, Batch 14, Loss: 1.6934113124167873\n",
      "Epoch 4, Batch 15, Loss: 2.7744285477333483\n",
      "Epoch 4, Batch 16, Loss: 0.6654713278476532\n",
      "Epoch 4, Batch 17, Loss: 0.8871118290406874\n",
      "Epoch 4, Batch 18, Loss: 0.6914691560621995\n",
      "Epoch 4, Batch 19, Loss: 0.5950941234468626\n",
      "Epoch 4, Batch 20, Loss: 0.6759696796658365\n",
      "Epoch 4, Batch 21, Loss: 0.8785692817980912\n",
      "Epoch 4, Batch 22, Loss: 0.3604078995867811\n",
      "Epoch 4, Batch 23, Loss: 0.3917051788766984\n",
      "Epoch 4, Batch 24, Loss: 0.5257924971429655\n",
      "Epoch 4, Batch 25, Loss: 0.9654678070477264\n",
      "Epoch 5, Batch 1, Loss: 0.6176548350599662\n",
      "Epoch 5, Batch 2, Loss: 0.5326331363394421\n",
      "Epoch 5, Batch 3, Loss: 0.7608432850057503\n",
      "Epoch 5, Batch 4, Loss: 0.5891247189028423\n",
      "Epoch 5, Batch 5, Loss: 0.27287186206249325\n",
      "Epoch 5, Batch 6, Loss: 0.41478573395327306\n",
      "Epoch 5, Batch 7, Loss: 0.525260193981827\n",
      "Epoch 5, Batch 8, Loss: 0.3859552128636138\n",
      "Epoch 5, Batch 9, Loss: 0.8898183812409313\n",
      "Epoch 5, Batch 10, Loss: 0.6744955025938517\n",
      "Epoch 5, Batch 11, Loss: 0.5363655287696587\n",
      "Epoch 5, Batch 12, Loss: 0.5090783147413896\n",
      "Epoch 5, Batch 13, Loss: 0.6056729693102683\n",
      "Epoch 5, Batch 14, Loss: 0.8491125107156589\n",
      "Epoch 5, Batch 15, Loss: 0.5011881724320864\n",
      "Epoch 5, Batch 16, Loss: 0.8333415291167402\n",
      "Epoch 5, Batch 17, Loss: 0.5080795441009207\n",
      "Epoch 5, Batch 18, Loss: 0.41768647231547706\n",
      "Epoch 5, Batch 19, Loss: 0.6763196832680156\n",
      "Epoch 5, Batch 20, Loss: 0.6131312328304371\n",
      "Epoch 5, Batch 21, Loss: 0.5722597991259879\n",
      "Epoch 5, Batch 22, Loss: 0.6725992395953562\n",
      "Epoch 5, Batch 23, Loss: 0.862127472645212\n",
      "Epoch 5, Batch 24, Loss: 0.5672224795498502\n",
      "Epoch 5, Batch 25, Loss: 0.3865200508866888\n",
      "Epoch 6, Batch 1, Loss: 0.6281340788551562\n",
      "Epoch 6, Batch 2, Loss: 0.39658938944429817\n",
      "Epoch 6, Batch 3, Loss: 0.5546008917160159\n",
      "Epoch 6, Batch 4, Loss: 0.8390989689538202\n",
      "Epoch 6, Batch 5, Loss: 1.6639987962894964\n",
      "Epoch 6, Batch 6, Loss: 1.2733712316234547\n",
      "Epoch 6, Batch 7, Loss: 1.639858249494504\n",
      "Epoch 6, Batch 8, Loss: 0.536468522859963\n",
      "Epoch 6, Batch 9, Loss: 0.364267987582654\n",
      "Epoch 6, Batch 10, Loss: 0.30792713280498685\n",
      "Epoch 6, Batch 11, Loss: 0.45410780114164756\n",
      "Epoch 6, Batch 12, Loss: 0.6173971803855385\n",
      "Epoch 6, Batch 13, Loss: 0.6529644189116736\n",
      "Epoch 6, Batch 14, Loss: 0.373361236061894\n",
      "Epoch 6, Batch 15, Loss: 0.5216300674837846\n",
      "Epoch 6, Batch 16, Loss: 0.6646128640784529\n",
      "Epoch 6, Batch 17, Loss: 0.37325274440925066\n",
      "Epoch 6, Batch 18, Loss: 0.6609817925645658\n",
      "Epoch 6, Batch 19, Loss: 0.27609543290851446\n",
      "Epoch 6, Batch 20, Loss: 0.6190699835161618\n",
      "Epoch 6, Batch 21, Loss: 1.231890807858159\n",
      "Epoch 6, Batch 22, Loss: 1.5377229006972313\n",
      "Epoch 6, Batch 23, Loss: 1.7513102799535907\n",
      "Epoch 6, Batch 24, Loss: 0.5540198342182128\n",
      "Epoch 6, Batch 25, Loss: 0.719015734421444\n",
      "Epoch 7, Batch 1, Loss: 0.3585673391303461\n",
      "Epoch 7, Batch 2, Loss: 0.4775009034372681\n",
      "Epoch 7, Batch 3, Loss: 0.3700980573507807\n",
      "Epoch 7, Batch 4, Loss: 0.5911639188016167\n",
      "Epoch 7, Batch 5, Loss: 0.12057329357925864\n",
      "Epoch 7, Batch 6, Loss: 1.269795512969044\n",
      "Epoch 7, Batch 7, Loss: 1.9819483731265461\n",
      "Epoch 7, Batch 8, Loss: 1.8629710717005974\n",
      "Epoch 7, Batch 9, Loss: 0.4141671389959547\n",
      "Epoch 7, Batch 10, Loss: 0.5642582234773561\n",
      "Epoch 7, Batch 11, Loss: 0.59549232540973\n",
      "Epoch 7, Batch 12, Loss: 0.5063313063998445\n",
      "Epoch 7, Batch 13, Loss: 0.5502372173301562\n",
      "Epoch 7, Batch 14, Loss: 0.9898110028384548\n",
      "Epoch 7, Batch 15, Loss: 1.267839036665209\n",
      "Epoch 7, Batch 16, Loss: 0.41368445861986913\n",
      "Epoch 7, Batch 17, Loss: 0.5971026511085984\n",
      "Epoch 7, Batch 18, Loss: 0.6651775889646725\n",
      "Epoch 7, Batch 19, Loss: 0.4818584578637275\n",
      "Epoch 7, Batch 20, Loss: 0.4373648798069445\n",
      "Epoch 7, Batch 21, Loss: 0.6692635902857886\n",
      "Epoch 7, Batch 22, Loss: 0.700377593084998\n",
      "Epoch 7, Batch 23, Loss: 0.8771477095093954\n",
      "Epoch 7, Batch 24, Loss: 0.3851077448779966\n",
      "Epoch 7, Batch 25, Loss: 0.6713964797908194\n",
      "Epoch 8, Batch 1, Loss: 0.6361619029291532\n",
      "Epoch 8, Batch 2, Loss: 0.7692942070737276\n",
      "Epoch 8, Batch 3, Loss: 1.5087370869366867\n",
      "Epoch 8, Batch 4, Loss: 0.8905907570719924\n",
      "Epoch 8, Batch 5, Loss: 0.6340222876035393\n",
      "Epoch 8, Batch 6, Loss: 1.8175452689542002\n",
      "Epoch 8, Batch 7, Loss: 2.5890554453401213\n",
      "Epoch 8, Batch 8, Loss: 0.9767018184287138\n",
      "Epoch 8, Batch 9, Loss: 0.41156807111355764\n",
      "Epoch 8, Batch 10, Loss: 0.36030191951063073\n",
      "Epoch 8, Batch 11, Loss: 0.26325065027611894\n",
      "Epoch 8, Batch 12, Loss: 0.4945922641315153\n",
      "Epoch 8, Batch 13, Loss: 0.4966742937190905\n",
      "Epoch 8, Batch 14, Loss: 0.908724117469671\n",
      "Epoch 8, Batch 15, Loss: 0.5629863119761733\n",
      "Epoch 8, Batch 16, Loss: 0.8251995652475498\n",
      "Epoch 8, Batch 17, Loss: 0.4830900094080136\n",
      "Epoch 8, Batch 18, Loss: 0.519081805667948\n",
      "Epoch 8, Batch 19, Loss: 0.3800997598617869\n",
      "Epoch 8, Batch 20, Loss: 0.6461999985955786\n",
      "Epoch 8, Batch 21, Loss: 0.21581939034409378\n",
      "Epoch 8, Batch 22, Loss: 0.7012894280674833\n",
      "Epoch 8, Batch 23, Loss: 0.5674151368098417\n",
      "Epoch 8, Batch 24, Loss: 0.6400620640697545\n",
      "Epoch 8, Batch 25, Loss: 0.9760833528479391\n",
      "Epoch 9, Batch 1, Loss: 0.47291821468802253\n",
      "Epoch 9, Batch 2, Loss: 0.6505887558381547\n",
      "Epoch 9, Batch 3, Loss: 0.7035582801731081\n",
      "Epoch 9, Batch 4, Loss: 0.8383103356798796\n",
      "Epoch 9, Batch 5, Loss: 0.4310137789570091\n",
      "Epoch 9, Batch 6, Loss: 0.3718069871626471\n",
      "Epoch 9, Batch 7, Loss: 0.7609905142328024\n",
      "Epoch 9, Batch 8, Loss: 0.6042356590804427\n",
      "Epoch 9, Batch 9, Loss: 0.18499593781896956\n",
      "Epoch 9, Batch 10, Loss: 0.44298355288678326\n",
      "Epoch 9, Batch 11, Loss: 0.41270889395127797\n",
      "Epoch 9, Batch 12, Loss: 0.5202941930074458\n",
      "Epoch 9, Batch 13, Loss: 0.513699162497196\n",
      "Epoch 9, Batch 14, Loss: 0.6403062559371853\n",
      "Epoch 9, Batch 15, Loss: 0.3423488427207948\n",
      "Epoch 9, Batch 16, Loss: 0.49177234583400026\n",
      "Epoch 9, Batch 17, Loss: 0.6254576677562683\n",
      "Epoch 9, Batch 18, Loss: 0.6764672930242468\n",
      "Epoch 9, Batch 19, Loss: 0.36040638312146983\n",
      "Epoch 9, Batch 20, Loss: 0.7696641492394007\n",
      "Epoch 9, Batch 21, Loss: 0.313255109971744\n",
      "Epoch 9, Batch 22, Loss: 0.5504395998062462\n",
      "Epoch 9, Batch 23, Loss: 0.6575493746799754\n",
      "Epoch 9, Batch 24, Loss: 0.3635051410495196\n",
      "Epoch 9, Batch 25, Loss: 0.5371673889604299\n",
      "Epoch 10, Batch 1, Loss: 0.18488859169742788\n",
      "Epoch 10, Batch 2, Loss: 0.3598283220579029\n",
      "Epoch 10, Batch 3, Loss: 0.3365840767025061\n",
      "Epoch 10, Batch 4, Loss: 0.3658432830375394\n",
      "Epoch 10, Batch 5, Loss: 0.31754267710322304\n",
      "Epoch 10, Batch 6, Loss: 0.4855860659461802\n",
      "Epoch 10, Batch 7, Loss: 0.5027631948512234\n",
      "Epoch 10, Batch 8, Loss: 0.7155050114576528\n",
      "Epoch 10, Batch 9, Loss: 0.6029821176526227\n",
      "Epoch 10, Batch 10, Loss: 0.33969706729877647\n",
      "Epoch 10, Batch 11, Loss: 0.3886423220920473\n",
      "Epoch 10, Batch 12, Loss: 0.5748316604202826\n",
      "Epoch 10, Batch 13, Loss: 0.3228650439160709\n",
      "Epoch 10, Batch 14, Loss: 0.834243847682916\n",
      "Epoch 10, Batch 15, Loss: 0.4537540124786203\n",
      "Epoch 10, Batch 16, Loss: 0.632655965602714\n",
      "Epoch 10, Batch 17, Loss: 0.8429529624707702\n",
      "Epoch 10, Batch 18, Loss: 0.6906311442274184\n",
      "Epoch 10, Batch 19, Loss: 0.5711199476289277\n",
      "Epoch 10, Batch 20, Loss: 0.4130631260230849\n",
      "Epoch 10, Batch 21, Loss: 0.5237224572523085\n",
      "Epoch 10, Batch 22, Loss: 0.5262352152965102\n",
      "Epoch 10, Batch 23, Loss: 0.6592183440737323\n",
      "Epoch 10, Batch 24, Loss: 0.7364703755107354\n",
      "Epoch 10, Batch 25, Loss: 0.8448491944160088\n",
      "Epoch 11, Batch 1, Loss: 0.3195266239898183\n",
      "Epoch 11, Batch 2, Loss: 0.6903446499268596\n",
      "Epoch 11, Batch 3, Loss: 0.5192218333385596\n",
      "Epoch 11, Batch 4, Loss: 0.26402194013351055\n",
      "Epoch 11, Batch 5, Loss: 0.2754331380638857\n",
      "Epoch 11, Batch 6, Loss: 0.3891577724832161\n",
      "Epoch 11, Batch 7, Loss: 0.33971559379299965\n",
      "Epoch 11, Batch 8, Loss: 0.45702616637698174\n",
      "Epoch 11, Batch 9, Loss: 0.6977359724645807\n",
      "Epoch 11, Batch 10, Loss: 1.2966448972460165\n",
      "Epoch 11, Batch 11, Loss: 1.8236671734017489\n",
      "Epoch 11, Batch 12, Loss: 0.22760014271715778\n",
      "Epoch 11, Batch 13, Loss: 0.7362484484534333\n",
      "Epoch 11, Batch 14, Loss: 0.616165966201005\n",
      "Epoch 11, Batch 15, Loss: 0.6278222671899788\n",
      "Epoch 11, Batch 16, Loss: 0.9236460648507\n",
      "Epoch 11, Batch 17, Loss: 0.38019804510823096\n",
      "Epoch 11, Batch 18, Loss: 0.3709274228863715\n",
      "Epoch 11, Batch 19, Loss: 0.7171334665602112\n",
      "Epoch 11, Batch 20, Loss: 0.6778220168264005\n",
      "Epoch 11, Batch 21, Loss: 0.35241311671867803\n",
      "Epoch 11, Batch 22, Loss: 0.4928341316336544\n",
      "Epoch 11, Batch 23, Loss: 0.452285623292311\n",
      "Epoch 11, Batch 24, Loss: 0.717058106297791\n",
      "Epoch 11, Batch 25, Loss: 0.7115177571502225\n",
      "Epoch 12, Batch 1, Loss: 0.6344681505829763\n",
      "Epoch 12, Batch 2, Loss: 0.4237700044812813\n",
      "Epoch 12, Batch 3, Loss: 0.5307012612785079\n",
      "Epoch 12, Batch 4, Loss: 0.32315639220984715\n",
      "Epoch 12, Batch 5, Loss: 0.4977135219505228\n",
      "Epoch 12, Batch 6, Loss: 0.23698112662966783\n",
      "Epoch 12, Batch 7, Loss: 0.5901868124623154\n",
      "Epoch 12, Batch 8, Loss: 0.7944008002523413\n",
      "Epoch 12, Batch 9, Loss: 0.32023157318153694\n",
      "Epoch 12, Batch 10, Loss: 0.4766851200308981\n",
      "Epoch 12, Batch 11, Loss: 1.0818802974996022\n",
      "Epoch 12, Batch 12, Loss: 0.6289887226487579\n",
      "Epoch 12, Batch 13, Loss: 0.4423809607740376\n",
      "Epoch 12, Batch 14, Loss: 0.46496661085177804\n",
      "Epoch 12, Batch 15, Loss: 0.49979267499997015\n",
      "Epoch 12, Batch 16, Loss: 0.554633471917686\n",
      "Epoch 12, Batch 17, Loss: 0.23153562637245195\n",
      "Epoch 12, Batch 18, Loss: 0.7590556270581017\n",
      "Epoch 12, Batch 19, Loss: 0.6876343365334572\n",
      "Epoch 12, Batch 20, Loss: 0.1642936002393323\n",
      "Epoch 12, Batch 21, Loss: 1.2286814795641532\n",
      "Epoch 12, Batch 22, Loss: 0.48517440968926856\n",
      "Epoch 12, Batch 23, Loss: 0.33532163554511024\n",
      "Epoch 12, Batch 24, Loss: 0.420208778500375\n",
      "Epoch 12, Batch 25, Loss: 0.5974225813857549\n",
      "Epoch 13, Batch 1, Loss: 0.4940968027292483\n",
      "Epoch 13, Batch 2, Loss: 0.440895302801939\n",
      "Epoch 13, Batch 3, Loss: 0.24226088616486452\n",
      "Epoch 13, Batch 4, Loss: 0.273312452412122\n",
      "Epoch 13, Batch 5, Loss: 0.986201426498879\n",
      "Epoch 13, Batch 6, Loss: 0.5180155184588688\n",
      "Epoch 13, Batch 7, Loss: 0.38341214700789494\n",
      "Epoch 13, Batch 8, Loss: 0.5503980778204071\n",
      "Epoch 13, Batch 9, Loss: 0.2873958724969774\n",
      "Epoch 13, Batch 10, Loss: 0.9144273412450996\n",
      "Epoch 13, Batch 11, Loss: 0.6508818924460793\n",
      "Epoch 13, Batch 12, Loss: 0.2741964105829917\n",
      "Epoch 13, Batch 13, Loss: 0.2646156442693876\n",
      "Epoch 13, Batch 14, Loss: 0.3772066810245371\n",
      "Epoch 13, Batch 15, Loss: 0.5153837239861703\n",
      "Epoch 13, Batch 16, Loss: 0.6568200528378876\n",
      "Epoch 13, Batch 17, Loss: 0.5360444813267528\n",
      "Epoch 13, Batch 18, Loss: 0.4291650269534445\n",
      "Epoch 13, Batch 19, Loss: 0.6282839058166789\n",
      "Epoch 13, Batch 20, Loss: 0.26200770357881337\n",
      "Epoch 13, Batch 21, Loss: 0.35287539098439563\n",
      "Epoch 13, Batch 22, Loss: 0.32773668394617833\n",
      "Epoch 13, Batch 23, Loss: 0.7053431724244528\n",
      "Epoch 13, Batch 24, Loss: 0.7577581963818654\n",
      "Epoch 13, Batch 25, Loss: 0.1825317682360878\n",
      "Epoch 14, Batch 1, Loss: 0.7946236310363809\n",
      "Epoch 14, Batch 2, Loss: 0.471647037828996\n",
      "Epoch 14, Batch 3, Loss: 0.3369692484066821\n",
      "Epoch 14, Batch 4, Loss: 0.7823919519915192\n",
      "Epoch 14, Batch 5, Loss: 1.2579006993928439\n",
      "Epoch 14, Batch 6, Loss: 0.647105320768689\n",
      "Epoch 14, Batch 7, Loss: 0.24415158015494914\n",
      "Epoch 14, Batch 8, Loss: 0.5614039610109673\n",
      "Epoch 14, Batch 9, Loss: 0.35431793208353185\n",
      "Epoch 14, Batch 10, Loss: 0.6066375951103535\n",
      "Epoch 14, Batch 11, Loss: 0.6510070742746631\n",
      "Epoch 14, Batch 12, Loss: 0.27061399901961447\n",
      "Epoch 14, Batch 13, Loss: 0.687966105046177\n",
      "Epoch 14, Batch 14, Loss: 0.97256794463017\n",
      "Epoch 14, Batch 15, Loss: 0.44498942644120376\n",
      "Epoch 14, Batch 16, Loss: 0.5429434534441312\n",
      "Epoch 14, Batch 17, Loss: 0.7097453930097992\n",
      "Epoch 14, Batch 18, Loss: 0.9118654868426416\n",
      "Epoch 14, Batch 19, Loss: 0.34115115109576244\n",
      "Epoch 14, Batch 20, Loss: 0.34932999895792255\n",
      "Epoch 14, Batch 21, Loss: 0.21524391269319532\n",
      "Epoch 14, Batch 22, Loss: 0.3485860269419995\n",
      "Epoch 14, Batch 23, Loss: 0.2586990007985735\n",
      "Epoch 14, Batch 24, Loss: 0.6711428225375444\n",
      "Epoch 14, Batch 25, Loss: 0.21914474833817751\n",
      "Epoch 15, Batch 1, Loss: 0.130172988139652\n",
      "Epoch 15, Batch 2, Loss: 0.42567114347614887\n",
      "Epoch 15, Batch 3, Loss: 0.5821757334997947\n",
      "Epoch 15, Batch 4, Loss: 0.27757148950918004\n",
      "Epoch 15, Batch 5, Loss: 0.4538381037055187\n",
      "Epoch 15, Batch 6, Loss: 0.41738303230011753\n",
      "Epoch 15, Batch 7, Loss: 0.3750963134266099\n",
      "Epoch 15, Batch 8, Loss: 0.420883585916435\n",
      "Epoch 15, Batch 9, Loss: 0.27476857919358944\n",
      "Epoch 15, Batch 10, Loss: 0.38422718801083355\n",
      "Epoch 15, Batch 11, Loss: 0.2309332046227866\n",
      "Epoch 15, Batch 12, Loss: 0.6639411912336121\n",
      "Epoch 15, Batch 13, Loss: 0.625961465885638\n",
      "Epoch 15, Batch 14, Loss: 1.4353413968296036\n",
      "Epoch 15, Batch 15, Loss: 1.0813460571656899\n",
      "Epoch 15, Batch 16, Loss: 0.29747649930736764\n",
      "Epoch 15, Batch 17, Loss: 0.28246807052943973\n",
      "Epoch 15, Batch 18, Loss: 0.47701957679547\n",
      "Epoch 15, Batch 19, Loss: 0.606507143001802\n",
      "Epoch 15, Batch 20, Loss: 0.5875920809609851\n",
      "Epoch 15, Batch 21, Loss: 0.8076372064389769\n",
      "Epoch 15, Batch 22, Loss: 0.40242487652644165\n",
      "Epoch 15, Batch 23, Loss: 0.3511588983442915\n",
      "Epoch 15, Batch 24, Loss: 0.2804313182428343\n",
      "Epoch 15, Batch 25, Loss: 0.9686878839261416\n"
     ]
    }
   ],
   "source": [
    "images=np.array([img.flatten() for img in images])\n",
    "labels=np.array([1 if label=='BA- cellulitis' else 0 for label in labels])\n",
    "input_size = images.shape[1]\n",
    "layers = [Dense(input_size, 1), Sigmoid()]\n",
    "model = Model(layers, learning_rate=0.01, batch_size=8, epochs=15)\n",
    "model.train(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping invalid path or .DS_Store: test_set/FU-athlete-foot\n",
      "Skipping invalid path or .DS_Store: test_set/BA- cellulitis\n",
      "Accuracy: 69.23%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.6923076923076923)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images, test_labels = drive.dataload('test_set')\n",
    "test_images = np.array([img.flatten() for img in test_images])\n",
    "test_labels = np.array([1 if label == 'BA- cellulitis' else 0 for label in test_labels])\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_predictions(model, images, labels, num_images=10):\n",
    "    # Get predictions\n",
    "    predictions = model.predict(images[:num_images])\n",
    "    predicted_labels = (predictions >= 0.5).astype(int).flatten()  # Threshold for binary classification\n",
    "    \n",
    "    # Plot images with predictions and true labels\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
    "    for i in range(num_images):\n",
    "        axes[i].imshow(images[i].reshape(20, 20), cmap='gray')  # Reshape to original image size\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f\"Pred: {predicted_labels[i]}\\nTrue: {labels[i]}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "index=np.arange(test_images.shape[0])\n",
    "np.random.shuffle(index)\n",
    "test_images=test_images[index]\n",
    "test_labels=test_labels[index]\n",
    "subset_images = test_images[:10]\n",
    "subset_labels = test_labels[:10]\n",
    "\n",
    "# Visualize predictions\n",
    "visualize_predictions(model, subset_images, subset_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model parameters\n",
    "def save_model(model, filename='model.pkl'):\n",
    "    model_params = {\n",
    "        'layers': [(layer.weights, layer.bias) for layer in model.layers if isinstance(layer, Dense)],\n",
    "        'input_size': model.layers[0].weights.shape[1]\n",
    "    }\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(model_params, f)\n",
    "\n",
    "# Save trained model\n",
    "save_model(model, 'skin_disease_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model parameters\n",
    "def load_model(filename='model.pkl'):\n",
    "    with open(filename, 'rb') as f:\n",
    "        model_params = pickle.load(f)\n",
    "\n",
    "    layers = []\n",
    "    for weights, bias in model_params['layers']:\n",
    "        dense_layer = Dense(weights.shape[1], weights.shape[0])\n",
    "        dense_layer.weights = weights\n",
    "        dense_layer.bias = bias\n",
    "        layers.append(dense_layer)\n",
    "        layers.append(Sigmoid())\n",
    "\n",
    "    return Model(layers, learning_rate=0.1, batch_size=8, epochs=10)\n",
    "\n",
    "# Load the trained model\n",
    "loaded_model = load_model('skin_disease_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Prediction function\n",
    "def predict(image):\n",
    "    # Preprocess the image\n",
    "    image = cv2.resize(image, (20, 20))  # Resize to 20x20\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "    image = image.astype('float32') / 255.0  # Normalize\n",
    "    flattened_image = image.flatten().reshape(-1, 1)  # Flatten and reshape\n",
    "\n",
    "    # Make a prediction\n",
    "    pred = loaded_model.predict(flattened_image.T)\n",
    "    return f\"Disease Detected: {'BA-cellulitis' if pred[0] == 1 else 'Foot ulcer'}\"\n",
    "\n",
    "# Create Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=gr.Image(type=\"numpy\", label=\"Upload Image\"),\n",
    "    outputs=gr.Label(label=\"Prediction\"),\n",
    "    title=\"Skin Disease Classifier\",\n",
    "    description=\"Upload an image of the skin, and the model will predict whether it's BA-cellulitis or Foot ulcer.\"\n",
    ")\n",
    "\n",
    "# Launch the web app\n",
    "interface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skindisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
