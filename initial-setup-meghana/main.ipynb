{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "4GAmo5Ly6YL6"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "class driveFile:\n",
        "  def __init__(self, mountpath):\n",
        "    import os\n",
        "    self.path = mountpath\n",
        "    from google.colab import drive\n",
        "    drive.mount(self.path, force_remount=True)\n",
        "\n",
        "  def dataload(self,folder_path):\n",
        "    img=[]\n",
        "    label=[]\n",
        "    import os\n",
        "    self.path1=os.path.join(self.path,folder_path)\n",
        "\n",
        "    if os.path.exists(self.path1):\n",
        "      for i in os.listdir(self.path1):\n",
        "        self.dis_path=os.path.join(self.path1,i)\n",
        "        # /content/drive/MyDrive/train_set/BA- cellulitis\n",
        "        if os.path.exists(self.dis_path) and '.DS_Store' not in self.dis_path:\n",
        "          for j in os.listdir(self.dis_path):\n",
        "           if j.endswith(('.jpg', '.png', '.jpeg')):\n",
        "              self.img_path = os.path.join(self.dis_path, j)\n",
        "              loaded_img= self.imgload(self.img_path)\n",
        "              if loaded_img is not None:\n",
        "                img.append(loaded_img)\n",
        "                label.append(i)\n",
        "              else:\n",
        "                 print(\"Skipping non-image file:\", j)\n",
        "          else:\n",
        "              print(\"Skipping invalid path or .DS_Store:\", self.dis_path)\n",
        "              continue\n",
        "      return np.array(img), np.array(label)\n",
        "    else:\n",
        "      return \"patherror\",\"patherror\"\n",
        "\n",
        "\n",
        "\n",
        "  def imgload(self,imgpath):\n",
        "    img=cv2.imread(imgpath)\n",
        "    if img is None:\n",
        "      print(f\"Failed to load image at {imgpath}\")\n",
        "      return None\n",
        "    img=cv2.resize(img,(20,20))\n",
        "    # v imp, usually 224*224 but here 20*20 \"downsampling or using a smaller image resolution before flattening it.\"\n",
        "    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "    img=img.astype('float32')/255.0\n",
        "    img_array=np.array(img)\n",
        "    return img_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "B8d5ONaK6YL8",
        "outputId": "ccdfa18d-7245-46c1-a209-da0186829923",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Skipping invalid path or .DS_Store: /content/drive/MyDrive/train_set/BA- cellulitis\n",
            "Skipping invalid path or .DS_Store: /content/drive/MyDrive/train_set/FU-athlete-foot\n"
          ]
        }
      ],
      "source": [
        "drive=driveFile('/content/drive')\n",
        "images,labels=drive.dataload('MyDrive/train_set')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "V7ImLFax6YL-"
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "    def __init__(self):\n",
        "        self.input=None\n",
        "        self.output=None\n",
        "    def forward(self,input):\n",
        "        # to be overridden\n",
        "        pass\n",
        "    def backward(self,output_gradient,learning_rate):\n",
        "        pass\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "AxcE6CCc6YL-"
      },
      "outputs": [],
      "source": [
        "class Dense(Layer):\n",
        "    def __init__(self,input_size,output_size):\n",
        "        self.weights=np.random.randn(output_size,input_size)*0.01\n",
        "        self.bias=np.random.randn(output_size,1)\n",
        "    def forward(self,input):\n",
        "        self.input=input\n",
        "        return np.dot(self.weights,self.input)+self.bias\n",
        "    def backward(self,output_gradient,learning_rate):\n",
        "        w_gradient = np.dot(output_gradient, self.input.T)  # (output_size, input_size)\n",
        "        b_gradient = np.sum(output_gradient, axis=1, keepdims=True)  # (output_size, 1)\n",
        "        input_gradient = np.dot(self.weights.T, output_gradient)  # (input_size, batch_size)\n",
        "        self.weights-=learning_rate * w_gradient\n",
        "        self.bias-=learning_rate * b_gradient\n",
        "        return input_gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "C80cnC7J6YL-"
      },
      "outputs": [],
      "source": [
        "class Activation(Layer):\n",
        "    def __init__(self,activation,activatn_derivative):\n",
        "        #activation is a variable pointing to a activation method,for ex sigmoid\n",
        "        self.activation=activation\n",
        "        self.activatn_derivative=activatn_derivative\n",
        "    def forward(self,input):\n",
        "        self.input=input\n",
        "        return self.activation(self.input)\n",
        "    def backward(self,output_gradient,learning_rate):\n",
        "        return np.multiply(output_gradient,self.activatn_derivative(self.input))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "CxIq84rx6YL_"
      },
      "outputs": [],
      "source": [
        "class Sigmoid(Activation):\n",
        "    def __init__(self):\n",
        "        def sigmoid(x):\n",
        "            return 1/(1+np.exp(-x))\n",
        "        def sigmoid_derivative(x):\n",
        "            s=sigmoid(x)\n",
        "            return s*(1-s)\n",
        "        super().__init__(sigmoid,sigmoid_derivative)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "2S2p60Yl6YL_"
      },
      "outputs": [],
      "source": [
        "class Loss(Layer):\n",
        "    def __init__(self,loss_fn,loss_fn_Derivative):\n",
        "        self.loss_fn=loss_fn\n",
        "        self.loss_fn_Derivative=loss_fn_Derivative\n",
        "    def forward(self,y_pred,y_true):\n",
        "        self.y_pred = y_pred\n",
        "        self.y_true = y_true\n",
        "        return self.loss_fn(y_pred, y_true)\n",
        "    def backward(self,y_pred,y_true):\n",
        "        return self.loss_fn_Derivative(y_pred,y_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "yDntE9b56YL_"
      },
      "outputs": [],
      "source": [
        "class BinaryCrossEntropy(Loss):\n",
        "    def __init__(self):\n",
        "        def bce(y_pred,y_true):\n",
        "            y_pred = np.clip(y_pred, 1e-10, 1 - 1e-10)  # Prevent extreme values\n",
        "            return -np.mean((y_true*np.log(y_pred))+((1-y_true)*np.log(1-y_pred)))\n",
        "        def bce_derivative(y_pred,y_true):\n",
        "            y_pred = np.clip(y_pred, 1e-10, 1 - 1e-10)  # Avoid division by zero\n",
        "            return -(y_true / y_pred) + ((1 - y_true) / (1 - y_pred))\n",
        "        super().__init__(bce,bce_derivative)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "kemRbwj_6YL_"
      },
      "outputs": [],
      "source": [
        "class Model:\n",
        "    def __init__(self, layers, learning_rate=0.01, batch_size=32, epochs=10):\n",
        "        self.layers = layers\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.loss_fn = BinaryCrossEntropy()\n",
        "\n",
        "    def forward(self, X):\n",
        "        for layer in self.layers:\n",
        "            X = layer.forward(X)\n",
        "        return X\n",
        "\n",
        "    def backward(self, loss_gradient):\n",
        "        for layer in reversed(self.layers):\n",
        "            loss_gradient = layer.backward(loss_gradient, self.learning_rate)\n",
        "\n",
        "    def train(self, X, y):\n",
        "        for epoch in range(self.epochs):\n",
        "            num_samples = X.shape[0]\n",
        "            index=np.arange(num_samples)\n",
        "            np.random.shuffle(index)\n",
        "            X=X[index]\n",
        "            y=y[index]\n",
        "            for i in range(0, num_samples, self.batch_size):\n",
        "                if(i+self.batch_size==num_samples):\n",
        "                    X_batch = X[i:num_samples]\n",
        "                    y_batch = y[i:num_samples]\n",
        "                else:\n",
        "                    X_batch = X[i:i + self.batch_size]\n",
        "                    y_batch = y[i:i + self.batch_size]\n",
        "\n",
        "                # Forward pass\n",
        "                predictions = self.forward(X_batch.T)\n",
        "\n",
        "                # Compute loss\n",
        "                loss = self.loss_fn.forward(predictions, y_batch.T)\n",
        "                print(f\"Epoch {epoch + 1}, Batch {i // self.batch_size + 1}, Loss: {loss}\")\n",
        "\n",
        "                # Backward pass\n",
        "                loss_gradient = self.loss_fn.backward(predictions, y_batch.T)\n",
        "                self.backward(loss_gradient)\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = self.forward(X.T)\n",
        "        return (predictions >= 0.5).astype(int).flatten()\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        predictions = self.predict(X)\n",
        "        accuracy = np.mean(predictions == y)\n",
        "        print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "        return accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "TtWgU84k6YMA",
        "outputId": "19e6a4ba-1b13-4798-80fc-6262aa6d0e7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 1, Loss: 0.7073090575496959\n",
            "Epoch 1, Batch 2, Loss: 1.494614909281991\n",
            "Epoch 1, Batch 3, Loss: 3.1666492886619824\n",
            "Epoch 1, Batch 4, Loss: 1.5032807608199996\n",
            "Epoch 1, Batch 5, Loss: 0.9837593782655697\n",
            "Epoch 1, Batch 6, Loss: 1.1694580604909715\n",
            "Epoch 1, Batch 7, Loss: 1.3794475000153739\n",
            "Epoch 1, Batch 8, Loss: 0.7193507066386816\n",
            "Epoch 1, Batch 9, Loss: 0.7832986901747838\n",
            "Epoch 1, Batch 10, Loss: 1.7392855443008504\n",
            "Epoch 1, Batch 11, Loss: 2.606959071852204\n",
            "Epoch 1, Batch 12, Loss: 1.092011203919495\n",
            "Epoch 1, Batch 13, Loss: 1.0278061569466956\n",
            "Epoch 1, Batch 14, Loss: 0.7336579916779185\n",
            "Epoch 1, Batch 15, Loss: 1.1486382031143554\n",
            "Epoch 1, Batch 16, Loss: 1.4007814002001324\n",
            "Epoch 1, Batch 17, Loss: 0.8849914503574999\n",
            "Epoch 1, Batch 18, Loss: 1.8653217376005393\n",
            "Epoch 1, Batch 19, Loss: 1.554890781462317\n",
            "Epoch 1, Batch 20, Loss: 0.7199939612881804\n",
            "Epoch 1, Batch 21, Loss: 0.6771493729824509\n",
            "Epoch 1, Batch 22, Loss: 0.8266242812088348\n",
            "Epoch 1, Batch 23, Loss: 0.5899636309690931\n",
            "Epoch 1, Batch 24, Loss: 0.38702275506914885\n",
            "Epoch 1, Batch 25, Loss: 1.6731276455636723\n",
            "Epoch 2, Batch 1, Loss: 0.8643619650741075\n",
            "Epoch 2, Batch 2, Loss: 0.5614909832127097\n",
            "Epoch 2, Batch 3, Loss: 1.106285424897345\n",
            "Epoch 2, Batch 4, Loss: 0.7248016640269881\n",
            "Epoch 2, Batch 5, Loss: 0.5214332599092827\n",
            "Epoch 2, Batch 6, Loss: 0.5775883281410179\n",
            "Epoch 2, Batch 7, Loss: 1.4253753663040902\n",
            "Epoch 2, Batch 8, Loss: 2.402616231409828\n",
            "Epoch 2, Batch 9, Loss: 0.5945446060054552\n",
            "Epoch 2, Batch 10, Loss: 1.1452983180132272\n",
            "Epoch 2, Batch 11, Loss: 1.278969345727109\n",
            "Epoch 2, Batch 12, Loss: 2.6721060856166097\n",
            "Epoch 2, Batch 13, Loss: 0.7692520612595141\n",
            "Epoch 2, Batch 14, Loss: 1.024309789389919\n",
            "Epoch 2, Batch 15, Loss: 0.5332490915908581\n",
            "Epoch 2, Batch 16, Loss: 0.6372884221110939\n",
            "Epoch 2, Batch 17, Loss: 0.6729873110870865\n",
            "Epoch 2, Batch 18, Loss: 0.568470402390184\n",
            "Epoch 2, Batch 19, Loss: 0.6978178675790203\n",
            "Epoch 2, Batch 20, Loss: 0.5430202550415535\n",
            "Epoch 2, Batch 21, Loss: 0.8509691412413359\n",
            "Epoch 2, Batch 22, Loss: 0.596558315265159\n",
            "Epoch 2, Batch 23, Loss: 0.7651710518795853\n",
            "Epoch 2, Batch 24, Loss: 0.46394370519450845\n",
            "Epoch 2, Batch 25, Loss: 0.3241937009267716\n",
            "Epoch 3, Batch 1, Loss: 0.6550480062189132\n",
            "Epoch 3, Batch 2, Loss: 1.061003673395326\n",
            "Epoch 3, Batch 3, Loss: 1.1878873876680052\n",
            "Epoch 3, Batch 4, Loss: 0.7654117682034549\n",
            "Epoch 3, Batch 5, Loss: 0.5248842397201372\n",
            "Epoch 3, Batch 6, Loss: 0.611133388388857\n",
            "Epoch 3, Batch 7, Loss: 2.059837795679225\n",
            "Epoch 3, Batch 8, Loss: 1.6239989702940079\n",
            "Epoch 3, Batch 9, Loss: 0.3233694641258768\n",
            "Epoch 3, Batch 10, Loss: 0.3865865491544541\n",
            "Epoch 3, Batch 11, Loss: 0.6826901154168673\n",
            "Epoch 3, Batch 12, Loss: 0.46644003943610246\n",
            "Epoch 3, Batch 13, Loss: 0.47539949816809396\n",
            "Epoch 3, Batch 14, Loss: 0.958069798605769\n",
            "Epoch 3, Batch 15, Loss: 0.6479357344912333\n",
            "Epoch 3, Batch 16, Loss: 0.5579118737778326\n",
            "Epoch 3, Batch 17, Loss: 0.9110083731819932\n",
            "Epoch 3, Batch 18, Loss: 1.5523053646942162\n",
            "Epoch 3, Batch 19, Loss: 0.6296591143693346\n",
            "Epoch 3, Batch 20, Loss: 0.8224713961953698\n",
            "Epoch 3, Batch 21, Loss: 0.9476890254936415\n",
            "Epoch 3, Batch 22, Loss: 0.3685943994020961\n",
            "Epoch 3, Batch 23, Loss: 1.4344773328128553\n",
            "Epoch 3, Batch 24, Loss: 3.423104124175455\n",
            "Epoch 3, Batch 25, Loss: 1.3476994634855053\n",
            "Epoch 4, Batch 1, Loss: 0.5686278890586259\n",
            "Epoch 4, Batch 2, Loss: 0.7125936015215468\n",
            "Epoch 4, Batch 3, Loss: 0.36331590939866876\n",
            "Epoch 4, Batch 4, Loss: 0.5986411505947411\n",
            "Epoch 4, Batch 5, Loss: 0.9536606641477694\n",
            "Epoch 4, Batch 6, Loss: 1.0955197128349965\n",
            "Epoch 4, Batch 7, Loss: 0.6114577283427267\n",
            "Epoch 4, Batch 8, Loss: 1.0713494187416337\n",
            "Epoch 4, Batch 9, Loss: 0.4534208132358366\n",
            "Epoch 4, Batch 10, Loss: 0.6108939794637902\n",
            "Epoch 4, Batch 11, Loss: 0.5694619508178655\n",
            "Epoch 4, Batch 12, Loss: 0.6318757666079424\n",
            "Epoch 4, Batch 13, Loss: 0.5406037084929096\n",
            "Epoch 4, Batch 14, Loss: 0.5604631459141662\n",
            "Epoch 4, Batch 15, Loss: 0.6423191281412728\n",
            "Epoch 4, Batch 16, Loss: 0.3807465516130756\n",
            "Epoch 4, Batch 17, Loss: 0.919821899524641\n",
            "Epoch 4, Batch 18, Loss: 1.6546026190544314\n",
            "Epoch 4, Batch 19, Loss: 1.0482416090599722\n",
            "Epoch 4, Batch 20, Loss: 1.051137313453204\n",
            "Epoch 4, Batch 21, Loss: 0.8327705568644668\n",
            "Epoch 4, Batch 22, Loss: 0.6340583703199101\n",
            "Epoch 4, Batch 23, Loss: 0.9697468213354099\n",
            "Epoch 4, Batch 24, Loss: 0.943144575396849\n",
            "Epoch 4, Batch 25, Loss: 0.977530338530179\n",
            "Epoch 5, Batch 1, Loss: 0.6913374302791786\n",
            "Epoch 5, Batch 2, Loss: 1.792086405230771\n",
            "Epoch 5, Batch 3, Loss: 0.8049927749377841\n",
            "Epoch 5, Batch 4, Loss: 0.7562045946825462\n",
            "Epoch 5, Batch 5, Loss: 0.5856745665964204\n",
            "Epoch 5, Batch 6, Loss: 1.0369683400097172\n",
            "Epoch 5, Batch 7, Loss: 0.8353067014992597\n",
            "Epoch 5, Batch 8, Loss: 0.48715823691129856\n",
            "Epoch 5, Batch 9, Loss: 0.4307604291525359\n",
            "Epoch 5, Batch 10, Loss: 0.9011728342041905\n",
            "Epoch 5, Batch 11, Loss: 0.1871909898208254\n",
            "Epoch 5, Batch 12, Loss: 0.38427493989827166\n",
            "Epoch 5, Batch 13, Loss: 0.34949485625586346\n",
            "Epoch 5, Batch 14, Loss: 1.0106116806745846\n",
            "Epoch 5, Batch 15, Loss: 1.4627156791157154\n",
            "Epoch 5, Batch 16, Loss: 0.5134521387062807\n",
            "Epoch 5, Batch 17, Loss: 0.4667806791260258\n",
            "Epoch 5, Batch 18, Loss: 0.1628892783156122\n",
            "Epoch 5, Batch 19, Loss: 1.71694090010852\n",
            "Epoch 5, Batch 20, Loss: 0.9969128855627449\n",
            "Epoch 5, Batch 21, Loss: 1.109862439539419\n",
            "Epoch 5, Batch 22, Loss: 0.5175238497599642\n",
            "Epoch 5, Batch 23, Loss: 2.1176409916867422\n",
            "Epoch 5, Batch 24, Loss: 1.5948798102556838\n",
            "Epoch 5, Batch 25, Loss: 0.4746836122239559\n",
            "Epoch 6, Batch 1, Loss: 0.4678545871293746\n",
            "Epoch 6, Batch 2, Loss: 0.3371151333799778\n",
            "Epoch 6, Batch 3, Loss: 0.37052050115003654\n",
            "Epoch 6, Batch 4, Loss: 0.5318123033795064\n",
            "Epoch 6, Batch 5, Loss: 0.8169975423926124\n",
            "Epoch 6, Batch 6, Loss: 0.506174824877213\n",
            "Epoch 6, Batch 7, Loss: 0.7323917610638069\n",
            "Epoch 6, Batch 8, Loss: 0.4554760871459724\n",
            "Epoch 6, Batch 9, Loss: 0.4981311028206108\n",
            "Epoch 6, Batch 10, Loss: 0.5157054717085101\n",
            "Epoch 6, Batch 11, Loss: 0.5122826826458693\n",
            "Epoch 6, Batch 12, Loss: 0.7382092990826856\n",
            "Epoch 6, Batch 13, Loss: 0.6829699069515089\n",
            "Epoch 6, Batch 14, Loss: 0.7811916196385855\n",
            "Epoch 6, Batch 15, Loss: 0.4976631900081151\n",
            "Epoch 6, Batch 16, Loss: 0.81613891599684\n",
            "Epoch 6, Batch 17, Loss: 1.3708166381477334\n",
            "Epoch 6, Batch 18, Loss: 0.2809990569372545\n",
            "Epoch 6, Batch 19, Loss: 0.5628248780506898\n",
            "Epoch 6, Batch 20, Loss: 0.6275653363232767\n",
            "Epoch 6, Batch 21, Loss: 0.4926779773145046\n",
            "Epoch 6, Batch 22, Loss: 0.4579386279683422\n",
            "Epoch 6, Batch 23, Loss: 0.4872816449531872\n",
            "Epoch 6, Batch 24, Loss: 0.4915249297086347\n",
            "Epoch 6, Batch 25, Loss: 0.4311387201305106\n",
            "Epoch 7, Batch 1, Loss: 0.7263684411561484\n",
            "Epoch 7, Batch 2, Loss: 1.8136467434789183\n",
            "Epoch 7, Batch 3, Loss: 0.5619137783479443\n",
            "Epoch 7, Batch 4, Loss: 0.5233643244662863\n",
            "Epoch 7, Batch 5, Loss: 0.3438374461438591\n",
            "Epoch 7, Batch 6, Loss: 0.35001102665464356\n",
            "Epoch 7, Batch 7, Loss: 0.4122297300572794\n",
            "Epoch 7, Batch 8, Loss: 0.6149841319392733\n",
            "Epoch 7, Batch 9, Loss: 0.9217055177533505\n",
            "Epoch 7, Batch 10, Loss: 0.3683832452121904\n",
            "Epoch 7, Batch 11, Loss: 0.3498366116447544\n",
            "Epoch 7, Batch 12, Loss: 0.7992720775496034\n",
            "Epoch 7, Batch 13, Loss: 0.35034203557227706\n",
            "Epoch 7, Batch 14, Loss: 0.760777488748813\n",
            "Epoch 7, Batch 15, Loss: 0.4752339900025676\n",
            "Epoch 7, Batch 16, Loss: 0.4294415798979092\n",
            "Epoch 7, Batch 17, Loss: 0.42026001420759096\n",
            "Epoch 7, Batch 18, Loss: 0.28012050798984967\n",
            "Epoch 7, Batch 19, Loss: 0.8352309128622271\n",
            "Epoch 7, Batch 20, Loss: 0.8206902530445013\n",
            "Epoch 7, Batch 21, Loss: 0.4805048683577212\n",
            "Epoch 7, Batch 22, Loss: 0.5561262157776841\n",
            "Epoch 7, Batch 23, Loss: 0.3259696492317642\n",
            "Epoch 7, Batch 24, Loss: 0.47446365669007673\n",
            "Epoch 7, Batch 25, Loss: 0.7264266767945041\n",
            "Epoch 8, Batch 1, Loss: 0.5766194583222624\n",
            "Epoch 8, Batch 2, Loss: 0.4089425564335715\n",
            "Epoch 8, Batch 3, Loss: 0.39006165112577806\n",
            "Epoch 8, Batch 4, Loss: 0.7075827230875011\n",
            "Epoch 8, Batch 5, Loss: 0.12982366758975086\n",
            "Epoch 8, Batch 6, Loss: 0.8909932405698637\n",
            "Epoch 8, Batch 7, Loss: 0.5422009899427201\n",
            "Epoch 8, Batch 8, Loss: 0.2802166705855433\n",
            "Epoch 8, Batch 9, Loss: 0.805576882138143\n",
            "Epoch 8, Batch 10, Loss: 0.7075402998915238\n",
            "Epoch 8, Batch 11, Loss: 1.0615546744635058\n",
            "Epoch 8, Batch 12, Loss: 0.39948976782774936\n",
            "Epoch 8, Batch 13, Loss: 0.5397256844023728\n",
            "Epoch 8, Batch 14, Loss: 0.4302669915410249\n",
            "Epoch 8, Batch 15, Loss: 0.4300611147783011\n",
            "Epoch 8, Batch 16, Loss: 0.41432204409714235\n",
            "Epoch 8, Batch 17, Loss: 0.37479916267567454\n",
            "Epoch 8, Batch 18, Loss: 0.7888436316602122\n",
            "Epoch 8, Batch 19, Loss: 0.5770984401172262\n",
            "Epoch 8, Batch 20, Loss: 0.9120146142722781\n",
            "Epoch 8, Batch 21, Loss: 0.38354840243159644\n",
            "Epoch 8, Batch 22, Loss: 0.38531997873775836\n",
            "Epoch 8, Batch 23, Loss: 0.3704221182016357\n",
            "Epoch 8, Batch 24, Loss: 0.5584370869508319\n",
            "Epoch 8, Batch 25, Loss: 1.1181597050344894\n",
            "Epoch 9, Batch 1, Loss: 0.41403866791326793\n",
            "Epoch 9, Batch 2, Loss: 0.30991106586764594\n",
            "Epoch 9, Batch 3, Loss: 0.5823987727716851\n",
            "Epoch 9, Batch 4, Loss: 0.7014103836581663\n",
            "Epoch 9, Batch 5, Loss: 0.3469216476964818\n",
            "Epoch 9, Batch 6, Loss: 0.38115189862072435\n",
            "Epoch 9, Batch 7, Loss: 0.4392490360068044\n",
            "Epoch 9, Batch 8, Loss: 0.5891889270624888\n",
            "Epoch 9, Batch 9, Loss: 0.4455779092484051\n",
            "Epoch 9, Batch 10, Loss: 0.4218820454331134\n",
            "Epoch 9, Batch 11, Loss: 0.41209755739670506\n",
            "Epoch 9, Batch 12, Loss: 0.1475166430422286\n",
            "Epoch 9, Batch 13, Loss: 0.6753526958219092\n",
            "Epoch 9, Batch 14, Loss: 0.6098733356416003\n",
            "Epoch 9, Batch 15, Loss: 0.6600129954901512\n",
            "Epoch 9, Batch 16, Loss: 0.5085663979553453\n",
            "Epoch 9, Batch 17, Loss: 0.871737366992442\n",
            "Epoch 9, Batch 18, Loss: 1.5500519880620727\n",
            "Epoch 9, Batch 19, Loss: 1.0246174811872277\n",
            "Epoch 9, Batch 20, Loss: 0.4531676640751989\n",
            "Epoch 9, Batch 21, Loss: 0.9431722441497081\n",
            "Epoch 9, Batch 22, Loss: 1.081275167801388\n",
            "Epoch 9, Batch 23, Loss: 0.9283895771745232\n",
            "Epoch 9, Batch 24, Loss: 0.4488391657974209\n",
            "Epoch 9, Batch 25, Loss: 0.5383015122221179\n",
            "Epoch 10, Batch 1, Loss: 0.38279004173101217\n",
            "Epoch 10, Batch 2, Loss: 0.8881566790566532\n",
            "Epoch 10, Batch 3, Loss: 0.7652604583773271\n",
            "Epoch 10, Batch 4, Loss: 1.0162005302749124\n",
            "Epoch 10, Batch 5, Loss: 0.8262726007816324\n",
            "Epoch 10, Batch 6, Loss: 0.9873435442333952\n",
            "Epoch 10, Batch 7, Loss: 0.5178141730410639\n",
            "Epoch 10, Batch 8, Loss: 0.26466609539621305\n",
            "Epoch 10, Batch 9, Loss: 0.512227516461444\n",
            "Epoch 10, Batch 10, Loss: 0.4228317503460861\n",
            "Epoch 10, Batch 11, Loss: 0.6430462047842445\n",
            "Epoch 10, Batch 12, Loss: 0.6630989684471208\n",
            "Epoch 10, Batch 13, Loss: 0.5428079433483424\n",
            "Epoch 10, Batch 14, Loss: 0.7515823232993373\n",
            "Epoch 10, Batch 15, Loss: 0.12937057782612585\n",
            "Epoch 10, Batch 16, Loss: 1.125743181225426\n",
            "Epoch 10, Batch 17, Loss: 0.45015166350994473\n",
            "Epoch 10, Batch 18, Loss: 0.7227636138844451\n",
            "Epoch 10, Batch 19, Loss: 0.4859362556162897\n",
            "Epoch 10, Batch 20, Loss: 0.7771582819902905\n",
            "Epoch 10, Batch 21, Loss: 0.5433446164724595\n",
            "Epoch 10, Batch 22, Loss: 0.36397122286739586\n",
            "Epoch 10, Batch 23, Loss: 0.3020041506407318\n",
            "Epoch 10, Batch 24, Loss: 0.3382287191373816\n",
            "Epoch 10, Batch 25, Loss: 0.5144489201852117\n",
            "Epoch 11, Batch 1, Loss: 0.5412545259066971\n",
            "Epoch 11, Batch 2, Loss: 1.2191240338017406\n",
            "Epoch 11, Batch 3, Loss: 1.6385052523104415\n",
            "Epoch 11, Batch 4, Loss: 0.7209739880850136\n",
            "Epoch 11, Batch 5, Loss: 0.7082565356082258\n",
            "Epoch 11, Batch 6, Loss: 0.3428190486346874\n",
            "Epoch 11, Batch 7, Loss: 0.786116401149533\n",
            "Epoch 11, Batch 8, Loss: 0.5486840069901563\n",
            "Epoch 11, Batch 9, Loss: 0.43603325859445463\n",
            "Epoch 11, Batch 10, Loss: 0.425995418880586\n",
            "Epoch 11, Batch 11, Loss: 0.3992180961758276\n",
            "Epoch 11, Batch 12, Loss: 0.4044955705720424\n",
            "Epoch 11, Batch 13, Loss: 0.5454130536832006\n",
            "Epoch 11, Batch 14, Loss: 0.46984616181661454\n",
            "Epoch 11, Batch 15, Loss: 0.4268831795139183\n",
            "Epoch 11, Batch 16, Loss: 0.21445587724298515\n",
            "Epoch 11, Batch 17, Loss: 0.7012568073916161\n",
            "Epoch 11, Batch 18, Loss: 1.1125101340271526\n",
            "Epoch 11, Batch 19, Loss: 0.4577769976295568\n",
            "Epoch 11, Batch 20, Loss: 0.33821304470258495\n",
            "Epoch 11, Batch 21, Loss: 0.2648153541456016\n",
            "Epoch 11, Batch 22, Loss: 0.6530494538388409\n",
            "Epoch 11, Batch 23, Loss: 0.5687165037285619\n",
            "Epoch 11, Batch 24, Loss: 0.2879167054070122\n",
            "Epoch 11, Batch 25, Loss: 0.22147683330606918\n",
            "Epoch 12, Batch 1, Loss: 0.4714042918741327\n",
            "Epoch 12, Batch 2, Loss: 0.3694701183364467\n",
            "Epoch 12, Batch 3, Loss: 1.0924430298277883\n",
            "Epoch 12, Batch 4, Loss: 1.047699039894641\n",
            "Epoch 12, Batch 5, Loss: 0.42736810350419974\n",
            "Epoch 12, Batch 6, Loss: 0.33356042757480486\n",
            "Epoch 12, Batch 7, Loss: 0.3671967136435336\n",
            "Epoch 12, Batch 8, Loss: 0.30343736719818587\n",
            "Epoch 12, Batch 9, Loss: 0.2539891278876428\n",
            "Epoch 12, Batch 10, Loss: 0.4787811741982448\n",
            "Epoch 12, Batch 11, Loss: 0.48955182942468267\n",
            "Epoch 12, Batch 12, Loss: 0.5519832588745578\n",
            "Epoch 12, Batch 13, Loss: 0.7380966169872512\n",
            "Epoch 12, Batch 14, Loss: 0.4784578042126292\n",
            "Epoch 12, Batch 15, Loss: 0.23743759419431879\n",
            "Epoch 12, Batch 16, Loss: 0.6440612536556642\n",
            "Epoch 12, Batch 17, Loss: 1.3803506356737698\n",
            "Epoch 12, Batch 18, Loss: 0.6072926067021687\n",
            "Epoch 12, Batch 19, Loss: 1.5000146992707803\n",
            "Epoch 12, Batch 20, Loss: 1.0396759960489579\n",
            "Epoch 12, Batch 21, Loss: 1.075610281534519\n",
            "Epoch 12, Batch 22, Loss: 0.5823842447737385\n",
            "Epoch 12, Batch 23, Loss: 0.4249302430879271\n",
            "Epoch 12, Batch 24, Loss: 0.4588223198850002\n",
            "Epoch 12, Batch 25, Loss: 0.3802068750029187\n",
            "Epoch 13, Batch 1, Loss: 0.30290650387062695\n",
            "Epoch 13, Batch 2, Loss: 0.40720327216506436\n",
            "Epoch 13, Batch 3, Loss: 1.2518625162467951\n",
            "Epoch 13, Batch 4, Loss: 0.4962435884691535\n",
            "Epoch 13, Batch 5, Loss: 0.5953581300845693\n",
            "Epoch 13, Batch 6, Loss: 0.3482127582684623\n",
            "Epoch 13, Batch 7, Loss: 0.43979453844899974\n",
            "Epoch 13, Batch 8, Loss: 0.34298315062087253\n",
            "Epoch 13, Batch 9, Loss: 0.680770321251281\n",
            "Epoch 13, Batch 10, Loss: 0.6598941966376606\n",
            "Epoch 13, Batch 11, Loss: 0.4544056665829659\n",
            "Epoch 13, Batch 12, Loss: 0.7580270771356779\n",
            "Epoch 13, Batch 13, Loss: 0.2201021697933656\n",
            "Epoch 13, Batch 14, Loss: 0.6626844744239678\n",
            "Epoch 13, Batch 15, Loss: 0.15601063533208437\n",
            "Epoch 13, Batch 16, Loss: 0.5991269578789011\n",
            "Epoch 13, Batch 17, Loss: 0.4656071137840332\n",
            "Epoch 13, Batch 18, Loss: 0.22052150177623764\n",
            "Epoch 13, Batch 19, Loss: 0.9304936379659009\n",
            "Epoch 13, Batch 20, Loss: 1.510025132228713\n",
            "Epoch 13, Batch 21, Loss: 0.15889034648802244\n",
            "Epoch 13, Batch 22, Loss: 0.45299261522487727\n",
            "Epoch 13, Batch 23, Loss: 0.40848974428301876\n",
            "Epoch 13, Batch 24, Loss: 0.34191664957737594\n",
            "Epoch 13, Batch 25, Loss: 0.18787421962424655\n",
            "Epoch 14, Batch 1, Loss: 0.5730496658744756\n",
            "Epoch 14, Batch 2, Loss: 0.3741104796442758\n",
            "Epoch 14, Batch 3, Loss: 0.6618603862857617\n",
            "Epoch 14, Batch 4, Loss: 0.32389838370935375\n",
            "Epoch 14, Batch 5, Loss: 1.1398131391772375\n",
            "Epoch 14, Batch 6, Loss: 0.8247300461217341\n",
            "Epoch 14, Batch 7, Loss: 0.39214186459821926\n",
            "Epoch 14, Batch 8, Loss: 0.33129337800842684\n",
            "Epoch 14, Batch 9, Loss: 0.29442807607229693\n",
            "Epoch 14, Batch 10, Loss: 0.47493959433244376\n",
            "Epoch 14, Batch 11, Loss: 0.5274414085755219\n",
            "Epoch 14, Batch 12, Loss: 0.39613809519200205\n",
            "Epoch 14, Batch 13, Loss: 0.4620822958683668\n",
            "Epoch 14, Batch 14, Loss: 0.44052912452389187\n",
            "Epoch 14, Batch 15, Loss: 0.32623780726524615\n",
            "Epoch 14, Batch 16, Loss: 0.3063551689931405\n",
            "Epoch 14, Batch 17, Loss: 0.3272226554663713\n",
            "Epoch 14, Batch 18, Loss: 0.23161681957109656\n",
            "Epoch 14, Batch 19, Loss: 0.2074006505423876\n",
            "Epoch 14, Batch 20, Loss: 0.3915651633153807\n",
            "Epoch 14, Batch 21, Loss: 0.8392401588628878\n",
            "Epoch 14, Batch 22, Loss: 0.46460592895446073\n",
            "Epoch 14, Batch 23, Loss: 0.6008429983515883\n",
            "Epoch 14, Batch 24, Loss: 0.16685381759388462\n",
            "Epoch 14, Batch 25, Loss: 0.4618821782200843\n",
            "Epoch 15, Batch 1, Loss: 0.33447803431769796\n",
            "Epoch 15, Batch 2, Loss: 0.521699648083076\n",
            "Epoch 15, Batch 3, Loss: 0.4186832572611115\n",
            "Epoch 15, Batch 4, Loss: 0.37642230309797675\n",
            "Epoch 15, Batch 5, Loss: 0.2877450349656415\n",
            "Epoch 15, Batch 6, Loss: 0.39241911271746377\n",
            "Epoch 15, Batch 7, Loss: 0.4975286620757072\n",
            "Epoch 15, Batch 8, Loss: 0.33524139773574746\n",
            "Epoch 15, Batch 9, Loss: 1.058877599828934\n",
            "Epoch 15, Batch 10, Loss: 0.7232903260968918\n",
            "Epoch 15, Batch 11, Loss: 0.5247707878374773\n",
            "Epoch 15, Batch 12, Loss: 0.4486943561524901\n",
            "Epoch 15, Batch 13, Loss: 0.2491316209329058\n",
            "Epoch 15, Batch 14, Loss: 0.25047677748956604\n",
            "Epoch 15, Batch 15, Loss: 1.1587567956657654\n",
            "Epoch 15, Batch 16, Loss: 0.3469994531099679\n",
            "Epoch 15, Batch 17, Loss: 0.8439982958184115\n",
            "Epoch 15, Batch 18, Loss: 0.6215551780141255\n",
            "Epoch 15, Batch 19, Loss: 0.24735977419725114\n",
            "Epoch 15, Batch 20, Loss: 0.30168238953696\n",
            "Epoch 15, Batch 21, Loss: 0.43949685288175455\n",
            "Epoch 15, Batch 22, Loss: 0.24051490470260156\n",
            "Epoch 15, Batch 23, Loss: 0.1796925490405457\n",
            "Epoch 15, Batch 24, Loss: 0.48828876876354466\n",
            "Epoch 15, Batch 25, Loss: 0.4571245148874784\n"
          ]
        }
      ],
      "source": [
        "images=np.array([img.flatten() for img in images])\n",
        "labels=np.array([1 if label=='BA- cellulitis' else 0 for label in labels])\n",
        "input_size = images.shape[1]\n",
        "layers = [Dense(input_size, 1), Sigmoid()]\n",
        "model = Model(layers, learning_rate=0.01, batch_size=8, epochs=15)\n",
        "model.train(images, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "z3SYQAtk6YMA",
        "outputId": "66350a9b-b4b5-414e-c085-ac4019781fbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping invalid path or .DS_Store: /content/drive/MyDrive/test_set/FU-athlete-foot\n",
            "Skipping invalid path or .DS_Store: /content/drive/MyDrive/test_set/BA- cellulitis\n",
            "Accuracy: 67.69%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.676923076923077"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "test_images, test_labels = drive.dataload('MyDrive/test_set')\n",
        "test_images = np.array([img.flatten() for img in test_images])\n",
        "test_labels = np.array([1 if label == 'BA- cellulitis' else 0 for label in test_labels])\n",
        "model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "aoSQ461p6YMB",
        "outputId": "2b1d1567-138e-47f4-fb36-23590ae26097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_predictions(model, images, labels, num_images=10):\n",
        "    # Get predictions\n",
        "    predictions = model.predict(images[:num_images])\n",
        "    predicted_labels = (predictions >= 0.5).astype(int).flatten()  # Threshold for binary classification\n",
        "\n",
        "    # Plot images with predictions and true labels\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
        "    for i in range(num_images):\n",
        "        axes[i].imshow(images[i].reshape(20, 20), cmap='gray')  # Reshape to original image size\n",
        "        axes[i].axis('off')\n",
        "        axes[i].set_title(f\"Pred: {predicted_labels[i]}\\nTrue: {labels[i]}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "index=np.arange(test_images.shape[0])\n",
        "np.random.shuffle(index)\n",
        "test_images=test_images[index]\n",
        "test_labels=test_labels[index]\n",
        "subset_images = test_images[:10]\n",
        "subset_labels = test_labels[:10]\n",
        "\n",
        "# Visualize predictions\n",
        "visualize_predictions(model, subset_images, subset_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "5YODOV916YMB"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Save the model parameters\n",
        "def save_model(model, filename='model.pkl'):\n",
        "    model_params = {\n",
        "        'layers': [(layer.weights, layer.bias) for layer in model.layers if isinstance(layer, Dense)],\n",
        "        'input_size': model.layers[0].weights.shape[1]\n",
        "    }\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(model_params, f)\n",
        "\n",
        "# Save trained model\n",
        "save_model(model, 'skin_disease_model.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "rvDhOpGR6YMB"
      },
      "outputs": [],
      "source": [
        "# Load the model parameters\n",
        "def load_model(filename='model.pkl'):\n",
        "    with open(filename, 'rb') as f:\n",
        "        model_params = pickle.load(f)\n",
        "\n",
        "    layers = []\n",
        "    for weights, bias in model_params['layers']:\n",
        "        dense_layer = Dense(weights.shape[1], weights.shape[0])\n",
        "        dense_layer.weights = weights\n",
        "        dense_layer.bias = bias\n",
        "        layers.append(dense_layer)\n",
        "        layers.append(Sigmoid())\n",
        "\n",
        "    return Model(layers, learning_rate=0.1, batch_size=8, epochs=10)\n",
        "\n",
        "# Load the trained model\n",
        "loaded_model = load_model('skin_disease_model.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "LgjhY0tQ6YMB",
        "outputId": "47cb2193-fd74-49a7-c5fd-6c01b820c20e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://213105e4f3166f09b6.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://213105e4f3166f09b6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Prediction function\n",
        "def predict(image):\n",
        "    # Preprocess the image\n",
        "    image = cv2.resize(image, (20, 20))  # Resize to 20x20\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
        "    image = image.astype('float32') / 255.0  # Normalize\n",
        "    flattened_image = image.flatten().reshape(-1, 1)  # Flatten and reshape\n",
        "\n",
        "    # Make a prediction\n",
        "    pred = loaded_model.predict(flattened_image.T)\n",
        "    return f\"Disease Detected: {'BA-cellulitis' if pred[0] == 1 else 'Foot ulcer'}\"\n",
        "\n",
        "# Create Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Image(type=\"numpy\", label=\"Upload Image\"),\n",
        "    outputs=gr.Label(label=\"Prediction\"),\n",
        "    title=\"Skin Disease Classifier\",\n",
        "    description=\"Upload an image of the skin, and the model will predict whether it's BA-cellulitis or Foot ulcer.\"\n",
        ")\n",
        "\n",
        "# Launch the web app\n",
        "interface.launch()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "skindisenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}